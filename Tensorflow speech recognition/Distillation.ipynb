{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distillation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEx9jye23Faa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install librosa==0.7\n",
        "!pip install adversarial-robustness-toolbox\n",
        "!pip install matplotlib\n",
        "!pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LBDXYJs3OWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndujDZVK3OtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "from scipy.io import wavfile\n",
        "import librosa\n",
        "import IPython.display as ipd\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import art\n",
        "import random\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod \n",
        "from art.metrics import empirical_robustness\n",
        "from art.metrics import clever_u\n",
        "from art.attacks.evasion import SaliencyMapMethod\n",
        "from art.attacks.evasion import DeepFool\n",
        "from art.utils import to_categorical as one_hot\n",
        "from art.metrics import loss_sensitivity as loss_sens\n",
        "from art.utils import second_most_likely_class as snd_likely\n",
        "from art.defences.transformer import DefensiveDistillation\n",
        "from art.defences.trainer import AdversarialTrainer as AdvTrainer\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwrBup2j3QTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_df = pd.read_pickle('./drive/My Drive/adver/train_df_dec10.pkl')\n",
        "#val_df = pd.read_pickle('./drive/My Drive/adver/valid_df_dec10.pkl')\n",
        "x_train = np.load('./drive/My Drive/adver/x_train_vec_dec10.npy')\n",
        "y_train = np.load('./drive/My Drive/adver/y_train_vec_dec10.npy')\n",
        "x_test = np.load('./drive/My Drive/adver/x_test_vec_dec10.npy')\n",
        "y_test = np.load('./drive/My Drive/adver/y_test_vec_dec10.npy')\n",
        "print(x_train[0].shape)\n",
        "\n",
        "def standardize(x , x_t):\n",
        "  mean = np.mean(x , axis = 0 , keepdims = True)\n",
        "  sd = np.std(x , axis = 0 , keepdims = True)\n",
        "  return (x - mean)/sd , (x_t - mean)/sd\n",
        "\n",
        "#x_train , x_test = standardize(x_train , x_test)\n",
        "\n",
        "\n",
        "mask = (y_test != 10)\n",
        "filtered_x_test = x_test[mask]\n",
        "filtered_y_test = y_test[mask]\n",
        "print(filtered_x_test.shape)\n",
        "\n",
        "mask = (y_train != 10)\n",
        "filtered_x_train = x_train[mask]\n",
        "filtered_y_train = y_train[mask]\n",
        "print(filtered_x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKYwIqgw3THE",
        "colab_type": "code",
        "outputId": "473694e4-3bbf-4cbe-d324-5314e101c562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "POSSIBLE_LABELS = 'yes no up down left right on off stop go unknown silence'.split(' ')\n",
        "print(POSSIBLE_LABELS)\n",
        "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
        "name2id = {name: i for i, name in id2name.items()}\n",
        "\n",
        "def get_class_weight(y):\n",
        "  ind, counts = np.unique(y, return_counts=True)\n",
        "  class_weight = {i: count for i, count in zip(ind, counts)}\n",
        "  class_weight = {ind: len(y)/val for ind, val in class_weight.items()}\n",
        "  return class_weight\n",
        "\n",
        "num_labels = 12\n",
        "\n",
        "def model_cloner(src):\n",
        "  model_copy= init_empty_model()\n",
        "  model_copy.set_weights(src.get_weights())\n",
        "  return model_copy\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def eval(cls , x , y):\n",
        "  _p = cls.predict(x)\n",
        "  y_pred = np.argmax(_p , axis = 1)\n",
        "  return accuracy_score(y_pred , y)\n",
        "\n",
        "def random_samplenp(x , y , sz):\n",
        "  perm = np.random.permutation(len(x))\n",
        "  xp = x[perm]\n",
        "  yp = y[perm]\n",
        "  mn = min(sz , len(x))\n",
        "  return xp[:mn] , yp[:mn]\n",
        "\n",
        "def get_avg_conf(orig_y , adv_y):\n",
        "  ret = 0\n",
        "  indiv = []\n",
        "  for i in range(len(orig_y)):\n",
        "    idx_1 = orig_y[i].argmax()\n",
        "    idx_2 = adv_y[i].argmax()\n",
        "    if idx_1 == idx_2:\n",
        "      indiv.append(0)\n",
        "      continue\n",
        "    ret += adv_y[i][idx_2]\n",
        "    indiv.append(adv_y[i][idx_2])\n",
        "  ret /= len(orig_y)\n",
        "  return (ret,indiv)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd4HcQsrtbEV",
        "colab_type": "text"
      },
      "source": [
        "## Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPi8_Lor3VUP",
        "colab_type": "code",
        "outputId": "b9ed2ad9-7b59-475e-da80-c028697bf18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "\n",
        "def init_empty_model(temperature):\n",
        "  \n",
        "  model = keras.Sequential([\n",
        "      keras.layers.InputLayer(input_shape=(128,32,1)),\n",
        "      keras.layers.Conv2D(64, kernel_size=(20,8), strides=1, padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(64, kernel_size=(10,4),\n",
        "      padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(64, kernel_size=(5,2), padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(64, kernel_size=(2,2), padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(64, kernel_size=(2,1), padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(500, activation=\"relu\"),\n",
        "      keras.layers.Dropout(.5),\n",
        "      keras.layers.Dense(250, activation=\"relu\"),\n",
        "      keras.layers.Dropout(.4),\n",
        "      keras.layers.Lambda(lambda x : x / temperature),\n",
        "      keras.layers.Dense(num_labels, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', \n",
        "                optimizer='nadam',\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeA-ZrrT9G15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher = init_empty_model(100)\n",
        "teacher.fit(x_train , y_train , epochs = 20 , batch_size = 256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE-UHKhg9xfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher.save_weights(\"./drive/My Drive/adver/teacher.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoLn8jntfxj",
        "colab_type": "text"
      },
      "source": [
        "## Student Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB5_zpBfBTxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_student_model(temperature):\n",
        "  \n",
        "  model = keras.Sequential([\n",
        "      keras.layers.InputLayer(input_shape=(128,32,1)),\n",
        "      keras.layers.Conv2D(64, kernel_size=(20,8), strides=1, padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(64, kernel_size=(10,4),\n",
        "      padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(64, kernel_size=(5,2), padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(64, kernel_size=(2,2), padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(64, kernel_size=(2,1), padding='same', activation='relu'),\n",
        "      keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(500, activation=\"relu\"),\n",
        "      keras.layers.Dropout(.5),\n",
        "      keras.layers.Dense(250, activation=\"relu\"),\n",
        "      keras.layers.Dropout(.4),\n",
        "      keras.layers.Lambda(lambda x : x / temperature),\n",
        "      keras.layers.Dense(num_labels, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', \n",
        "                optimizer='nadam',\n",
        "                metrics=['binary_crossentropy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "839glnN8B5CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "student = init_student_model(20)\n",
        "student.fit(x_train , results , epochs = 20 , batch_size = 256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoBQQ1UtB_7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distilled_model = init_empty_model(1)\n",
        "distilled_model.set_weights(student.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q65oGdHFkSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save to disk\n",
        "student.save_weights(\"./drive/My Drive/adver/student2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}